# ğŸ¤– FinTechX API - API Inteligente com LLM

Uma API moderna que transforma perguntas em linguagem natural em consultas SQL usando OpenAI GPT, conectada ao banco de dados Northwind.

**Desenvolvido por Carlos Henrique Stow Chaves**

## âœ¨ CaracterÃ­sticas

- **ğŸ¤– LLM Integration**: OpenAI GPT para geraÃ§Ã£o inteligente de SQL
- **ğŸ—„ï¸ Database**: MySQL [base teste Northwind na AWS]
- **âš¡ FastAPI**: API moderna e rÃ¡pida
- **ğŸ¨ Painel**: Interface web para utilizaÃ§Ã£o alem da API
- **ğŸ›¡ï¸ SeguranÃ§a**: ValidaÃ§Ã£o e sanitizaÃ§Ã£o de dados
- **ğŸ“Š SerializaÃ§Ã£o Inteligente**: Tratamento automÃ¡tico de qualquer tipo de dado

## ğŸš€ Quick Start

### 1. ConfiguraÃ§Ã£o do Ambiente

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd laborit

# Crie um ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o das VariÃ¡veis de Ambiente

```bash
# Copie o arquivo de exemplo
cp env.example .env

# Edite com suas credenciais
nano .env
```

Configure as seguintes variÃ¡veis:
```env
OPENAI_API_KEY=sua_chave_openai
DATABASE_URL=mysql://user:password@host:port/northwind
```

### 3. Executar a API

```bash
# Iniciar a API
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 3.1. Executar com Docker (Alternativa)

```bash
# Build e execuÃ§Ã£o com Docker Compose
docker-compose up --build

# Ou apenas build da imagem
docker build -t fintechx-api .
docker run -p 8000:8000 -e OPENAI_API_KEY=sua_chave fintechx-api
```

### 4. Acessar o Painel

Foi criado um front basico que estÃ¡ integrado Ã  API e Ã© servido automaticamente na rota raiz.

**Local:** Acesse: **http://localhost:8000/**

**ProduÃ§Ã£o:** Acesse: **https://laborit-test-gt3b.vercel.app/**


### Exemplos de Perguntas:

- "Quais sÃ£o os produtos mais populares entre os clientes corporativos?"
- "Quais sÃ£o os produtos mais vendidos em termos de quantidade?"
- "Qual Ã© o volume de vendas por cidade?"
- "Quais sÃ£o os clientes que mais compraram?"
- "Quais sÃ£o os produtos mais caros da loja?"
- "Quais sÃ£o os fornecedores mais frequentes nos pedidos?"
- "Quais os melhores vendedores?"
- "Qual Ã© o valor total de todas as vendas realizadas por ano?"
- "Qual Ã© o valor total de vendas por categoria de produto?"
- "Qual o ticket mÃ©dio por compra?"

## ğŸ”§ API Endpoints

### GET `/`
Painel web da aplicaÃ§Ã£o

### POST `/api/query`
Consulta principal em linguagem natural

```bash
curl -X POST "http://localhost:8000/api/query" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Quais sÃ£o os produtos mais populares entre os clientes corporativos?",
    "limit": 10
  }'
```

### GET `/api/health`
Health check da aplicaÃ§Ã£o

```bash
curl http://localhost:8000/api/health
```

## ğŸ—ï¸ Arquitetura

```
laborit/
â”œâ”€â”€ index.py                 # Entry point para Vercel
â”œâ”€â”€ vercel.json              # ConfiguraÃ§Ã£o Vercel
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # AplicaÃ§Ã£o FastAPI
â”‚   â”œâ”€â”€ api/routes.py        # Rotas da API
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_service.py   # IntegraÃ§Ã£o OpenAI
â”‚   â”‚   â””â”€â”€ sql_service.py   # ExecuÃ§Ã£o SQL
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ serializers.py   # SerializaÃ§Ã£o inteligente
â”‚   â”‚   â”œâ”€â”€ validators.py    # ValidaÃ§Ã£o de dados
â”‚   â”‚   â””â”€â”€ prompts.py       # Prompts do LLM
â”‚   â””â”€â”€ models/schemas.py    # Schemas Pydantic
â”œâ”€â”€ index.html               # Painel WEB
â”œâ”€â”€ requirements.txt         # DependÃªncias
â””â”€â”€ LICENSE                  # LicenÃ§a MIT
```

## ğŸš€ SerializaÃ§Ã£o Inteligente

O projeto utiliza um sistema de serializaÃ§Ã£o inteligente que:

- **ğŸ”„ AutomÃ¡tico**: Trata qualquer tipo de dado automaticamente
- **ğŸ§  Inteligente**: Detecta o tipo e aplica a melhor estratÃ©gia
- **âš¡ Performance**: Otimizado para diferentes contextos
- **ğŸ›¡ï¸ Robusto**: MÃºltiplas estratÃ©gias de fallback

```

## ğŸ”’ SeguranÃ§a

- **SQL Injection Protection**: ValidaÃ§Ã£o rigorosa de consultas
- **Input Sanitization**: Limpeza de dados de entrada
- **Error Handling**: Tratamento seguro de erros

## ğŸš€ Deploy

### Vercel

1. Conecte seu repositÃ³rio ao Vercel
2. Configure as variÃ¡veis de ambiente:
   - `DATABASE_URL`
   - `OPENAI_API_KEY`
   - `OPENAI_MODEL`
   - `APP_NAME`
   - `APP_VERSION`
   - `DEBUG`
3. Deploy automÃ¡tico a cada push

**URL da API:** `https://laborit-test-gt3b.vercel.app/api/`  
**URL da DOC:** `https://laborit-test-gt3b.vercel.app/docs/`  
**URL do Painel:** `https://laborit-test-gt3b.vercel.app/`

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

**Desenvolvido por Carlos Henrique Stow Chaves**
